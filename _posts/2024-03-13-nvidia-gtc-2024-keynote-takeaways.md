---
layout: post
title: Highlights from Jensen Huang's Keynote 2024 GTC 
subtitle: NVIDIA Blackwell GPU Architecture Overview 
comments: true
author: Kateryna M
---

## Key Highlights from Jensen Huang's Keynote 2024 GTC

- **Introduction of Blackwell Architecture**: A leap forward in AI technology, promising to revolutionize various industries.
- **Project GROOT Announcement**: Showcases advancements towards the human-robot future, bringing us closer to more interactive and capable robots.
- **Collaboration with Apple Vision Pro**: Nvidia's venture into the Omniverse, aiming to enhance virtual reality experiences.
- **Digital Twin of the Planet**: An ambitious project to recreate the entire planet digitally for better weather forecasting and more.

## Notable Announcements and Developments

- **Humanoid Robots in Development**: Demonstrated potential applications across factories, healthcare, and science, signaling the future may not be far off.
- **Isaac Perceptor SDK**: New software aimed at robotic arms and vehicles, providing them with greater insight and intelligence.
- **Omniverse Cloud Streaming to Apple Vision Pro**: A step towards more immersive virtual environments, powered by Nvidia's cutting-edge technology.
- **Partnership with Nissan**: Highlighted the potential for AI in customizing new car options, showcasing a blend of technology and consumer choice.
- **Siemens Collaboration**: Nvidia's technology will be used to boost productivity and efficiency in virtual warehouses, marking significant industrial application.
- **Advancements in Healthcare**: Nvidia building models to aid researchers worldwide, speeding up drug discovery processes.
- **Earth-2 APIs for Better Weather Forecasting**: A collaboration with The Weather Company to improve predictions and save lives.

# NVIDIA Blackwell GPU Architecture Overview

## Introduction
The NVIDIA Blackwell architecture introduces a significant leap forward in generative AI accelerator technology, incorporating the B200 and B100 accelerators. Named in honor of Dr. David Harold Blackwell, a pioneer in statistics and mathematics, this next-generation architecture is designed to redefine performance, flexibility, and efficiency in the realms of datacenter and high-performance computing (HPC).

## Features and Capabilities

### Dual-Die Chiplet Design
- Integrates two reticle-sized GPU dies within a single package, embracing a chiplet-based approach for flagship accelerators.
- Enables substantial increases in transistor count, computing power, and memory capacity.

### Transistor Count and Memory
- Features a total of 208 billion transistors (104 billion per die), marking a 30% enhancement over its predecessors.
- Equipped with 8 stacks of HBM3E memory, providing 192GB of VRAM and an impressive 8TB/sec of memory bandwidthâ€”nearly 2.4x the bandwidth of the H100 accelerator.

### Compute Performance
- Optimized tensor cores support operations down to FP4 precision, enabling up to 10 PetaFLOPS of FP8 performance and 20 PFLOPS of FP4 performance for inference tasks, demonstrating significant progress in AI and machine learning capabilities.

### NVLink Interconnect
- Utilizes the NV-High Bandwidth Interface (NV-HBI), offering 10TB/second of bandwidth for inter-die communication. This feature ensures the two dies operate seamlessly as one unified CUDA GPU, eliminating potential performance bottlenecks.

### Efficiency and Performance
- Despite adhering to a 4nm-class TSMC 4NP manufacturing process, Blackwell achieves a 4x increase in training performance and a 30x improvement in inference performance, all while realizing 25x greater energy efficiency compared to earlier generations.


